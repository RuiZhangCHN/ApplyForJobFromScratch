# 中文分词

## （一）基于规则的分词方法

#### 1. 最大匹配算法
匹配算法就是首先使用一个词表，进行N-gram最长匹配。匹配方向可以是正向匹配、反向匹配、或者双向匹配。
据说90%的文本双向匹配的结果是一致的，剩下的9%会出现歧义但会有一种解法是正确的，只有1%的情况两种方向上的匹配都会失败。
#### 2. 最短路径算法
最短路径的方法包括Dijkstra算法和N最短路径分词。

先简单复习一下Dijkstra。这是一种贪心的单源最短路径算法，它的主要特点是从起始点开始，采用贪心算法的策略，每次遍历到始点距离最近且未访问过的顶点的邻接节点，直到扩展到终点为止。

N-最短路径是Dijkstra算法的延申，具体可以参考《[Hanlp中N最短路径分词详细介绍](http://blog.itpub.net/31524777/viewspace-2639248/)》。

## （二）基于统计的分词方法

#### 1. N-gram语言模型
最基本的链式法则：P(w_1,w_2,...,w_m) = P(w_1)P(w_2|w_1)P(w_3|w_1,w_2)...P(w_m|w_1,w_2,...w_{m-1})

使用频率技术来计算n元条件的概率：
P(w_i|w_{i-(n-1)}, ..., w_{i-1}) = count(w_{i-(n-1)}, ..., w_{i-1}, w_i) / count(w_{i-(n-1), ..., w_{i-1}})
【分子分母相差在于w_i词有没有出现】

由于链式法则不好计算，通常会设定n-gram范围，比如n=2或者n=3。当n太大的时候相应的序列出现次数也会减少。
因此对于可能出现的分子分母为0的情况，通常需要进行平滑。

#### 2. 隐马尔科夫模型HMM
将四种状态作为观测状态：{B（词首）、M（词钟）、E（词尾）、S（独立成词）}
在HMM中我们期望求解P(o|λ)，由贝叶斯公式计算可以得到：
P(o|λ) = P(o,λ)/P(λ) = P(λ|o)P(o)/P(λ)
由于λ是给定输入，因此P(λ)是常数可以忽略。而o为观测，故最大化P(o|λ)等价于最大化P(λ|o)P(o)。

对上式做马尔可夫假设，得到：
P(λ|o) = P(λ_1|o_1)P(λ_2|o_2)...P(λ_n|o_n)

同时，对于P(o)，有：
P(o) = P(o_1)P(o_2|o_1)P(o_3|o_1,o_2)...P(o_n|o_1,o_2,...o_{n-1})

在HMM中进行齐次马尔科夫假设，假定输出仅与上一个输出有关：
P(o) = P(o_1)P(o_2|o_1)P(o_3|o_2)...P(o_n|o_{n-1})

故有：
P(λ|o)P(o)~P(o_1)P(λ_1|o_1)P(o_2|o_1)P(λ_2|o_2)...

通常而言，可以使用维特比算法计算max P(λ|o)P(o)。

#### 3. 条件随机场CRF

#### 4. 词感知机

#### 5. 最大熵模型

#### 6. 支持向量机SVM
