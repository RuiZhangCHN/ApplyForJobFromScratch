# 深度学习

### （一）神经网络基本原理

> 详细描述梯度下降法过程及原理；什么是梯度消失和梯度爆炸？解决梯度消失和梯度爆炸的方案都有哪些？

- **梯度：** 在微积分中对多元函数求偏导数，将所求的各个参数的偏导数以向量的形式表达出来，就是梯度。梯度向量从几何意义上讲，是函数变化量增加最快的地方。沿着梯度向量方向容易找到函数的最大值；沿着向量相反的方向，容易找到函数的最小值。
- **梯度下降法：** 梯度下降法的计算过程是沿梯度下降的方向求解极小值（或者沿梯度上升的方向求解极大值）
- **梯度消失和梯度爆炸的原因：** 在sigmoid激活函数中，其求导图像呈现单驼峰状。由求导结果可知其导数取值范围在0-0.25之间，而初始化的网络权值|w|通常小于1。因此当层数增多时，许多小于0的值不断相乘，就会导致梯度消失情况。反之，当权值|w|过大时，容易导致相乘结果大于1，通过许多大于1的值不断相乘，就会产生梯度爆炸。
- **解决方法：** （1）换用ReLU, LeakyReLU, ELU等函数 （2）BatchNormalization （3）残差网络 （4）预训练+微调 （5）梯度剪切/正则

### （二）循环神经网络
> 常见的循环神经网络都有哪些？他们的优缺点及应用场景？详细描述之前其中一种网络结构及其推导过程。

待整理
